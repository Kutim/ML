# 3. 机器学习概述

## 3.1 机器学习基本概念

召回率（Recall Rate）与准确率（Precision Rate）的关系。

|          | 实际为真           | 实际为假           |
| -------- | ------------------ | ------------------ |
| 预测为真 | TP                 | FP（其实就是误报） |
| 预测为假 | FN（其实就是漏报） | TN                 |

$$
召回率=TP/(TP+FN)
$$

$$
准确率=TP/(TP+FP)
$$

## 3.2 数据集

### 3.2.1 KDD99数据

### 3.2.2 HTTP DATASET CSIC2010

包含大量标注过的针对Web服务的36000个正常请求以及25000个攻击请求，攻击类型包括sql 注入、缓冲区溢出、信息泄露、文件包含、xss等。

### 3.2.3 SEA 数据集

公开的检测伪装者攻击的数据集SEA，该数据集被广泛用于内部伪装者威胁检测研究。

http://www.schonlau.net/

### 3.2.4 ADFA-LD 数据集

主机级入侵检测系统的数据集合。已经将各类系统调用完成了特征化，并针对攻击类型进行了标注。

https://www.unsw.adfa.edu.au/

### 3.2.5 Alexa域名数据

Alexa 排名是根据用户下载安装 Alexa Tools Bar 嵌入到IE、FireFox等浏览器，从而监控器访问的网站数据进行统计的。

### 3.2.6 Scikit_Learn 数据集

iris鸢尾植物：萼片和花瓣的长宽。

### 3.2.7 MNIST数据集

包含各种手写数字图片

http://yann.lecun.com/exdb/mnist/

### 3.2.8 Moive Review Data

包含1000条正面评论和1000条负面评论。

<http://www.cs.cornell.edu/people/pabo/movie-review-data/>

### 3.2.9 SpamBase数据集

入门级的垃圾邮件分类训练集，已经特征化的数据，对应的特征是统计的关键字以及特殊符号的词频，一共58个属性，其中最后一个是垃圾邮件的标记位。

http://archive.ics.uci.edu/ml/datasets/Spambase

### 3.2.10 Enron数据集

使用 Enron公司的归档邮件来研究文档分类、词性标注、垃圾邮件识别。

http://www2.aueb.gr/users/ion/data/enron-spam/

## 3.3 特征提取

### 3.3.1 数字型特征提取

数字型特征可以直接作为特征，但是对于一个多维的特征，某一个特征的取值范围特别大，很可能导致其他特征对结果的影响被忽略，这时我们需要对数字型特征进行预处理，常见的预处理方式有：

1. 标准化

   数据的标准化是将数据按比例缩放，使之落入一个小的特定区间。

   ```python
   from sklearn import preprocessing
   import numpy as np
   X = np.array([[1., -1., 2.],
                 [2., 0., 0.],
                 [0., 1., -1.]])
   X_scaled = preprocessing.scale(X)
   ```

   ​

2. 正则化

   用一组与原不适定问题相“邻近”的适定问题的解，去逼近原问题的解，这种方法称为正则化方法。

   ```python
   X_normalized = preprocessing.normalize(X, norm='l2')
   ```

   ​

3. 归一化

   把数据变为（0，1）之间的小数。主要是为了方便数据处理，因为将数据映射到0～1范围之内，可以使处理过程更加便捷、快速。

   ```
   min_max_scaler = preprocessing.MinMaxScaler()
   X_train_minmax = min_max_scaler.fit_transform(x_train)
   ```

   
### 3.3.2 文本型特征提取

   文本型数据提取特征相对 数字型更要复杂很多，本质上是做单词切分，不同的单词当作一个新的特征。

   ```python
   measurements = [
       {'city':'A', 'temperature':33},
       {'city':'B', 'temperature':12},
       {'city':'C', 'temperature':18},
   ]
   
   from sklearn.feature_extraction import DictVectorizer
   vec = DictVectorizer()
   vec.fit_transform(measurements).toarray()
   
   ```

   文本特征提取有两个非常重要的模型：

   - 词集模型：单词构成的集合，集合中每个元素都只有一个，即词集中的每个单词都只有一个。
   - 词袋模型：如果一个单词在文档中出现不止一次，并统计其出现的次数（频数）

   词袋是在词集的基础上增加了频率的维度。

   ```python
   # 导入相关函数库
   from sklearn.feature_extraction.text import CountVectorizer
   
   # 实例化分词对象
   vectorizer = CountVectorizer(min_df=1)
   
   # 将文本进行词袋处理
   
   corpus =[
       'this is the first document.',
       'this is the second second document.',
   ]
   X = vectorizer.fit_transform(corpus)
   
   # 获取对应的特征名称
   vectorizer.get_feature_name()
   
   # 获取词袋数据
   X.toarray()
   ```

### 3.3.3 数据读取

   常见格式为CSV，每行记录一个向量，其中最后一列为标记。		

   

## 3.4	 效果验证

   效果验证常使用交叉验证。

```python
# 训练样本、测试样本分割

from sklearn.model_selection import train_test_split

```

   为了提高验证的准确度，比较常见的方法是使用K折交叉验证。这个方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，十折交叉验证是最常用的。

```python
from sklearn.model_selection import cross_val_score
clf = svm.SVC(kernel='liner', C=1)
scores = cross_val_score(clf, iris.data, iris.target, cv=5)

```

