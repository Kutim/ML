# 多层感知机与DNN算法

​	隐藏层大于1，即所谓的多层感知机和DNN算法。

## 15.1 神经网络与深度学习

​	神经网络由输入层、隐藏层和输出层组成。

​	如果隐藏层只有一层，就是最简单的单层神经网络。

​	如果隐藏层具有多层，就是多层感知机。深度学习就是多层感知机的一种。

​	狭义的多层感知机，要求必须是全连接的（每个隐藏层的任何一个节点，都与下一层隐藏层的全部节点连接）。

​	深度神经网络（DNN）就是一种全连接的多层感知机。常见的深度学习包括DNN、卷积神经网络（CNN）、循环神经网络（RNN）

## 15.2 TensorFlow 编程模型

​	Tensor也叫张量，集所谓的N维数组；Flow也叫流，即所谓基于数据流图的计算。TensorFlow为张量从流图的一段流动到另一端的计算过程。

​	TensorFlow计算模型中，最基础的4个组件是操作、张量、变量和会话。

### 15.2.1 操作

​	把算法表示成一个个操作的叠加。

​	一个操作可以有零个或多个输入，产生零个或多个输出。

### 15.2.2 张量

​	计算图中，每个边就代表数据从一个操作流到另一个操作。这些数据被表示为张量，一个张量可以看作多维的数组或者高维的矩阵。

​	TensorFlow中的张量，并没有保存任何值，张量仅仅提供了访问数值的一个接口，可以看成数值的一种引用。

### 15.2.3 变量

​	计算图中可以改变的节点。比如当计算权重的时候，随着迭代的进行，每次权重的值会发生相应的变化，这样的值就可以当作变量。

​	在实际处理时，一般把需要训练的之指定为变量。

### 15.2.4 会话

​	在TensorFlow中，所有操作都必须在会话中执行，会话负责分配和管理各种资源。

## 15.3 TensorFlow的运行模式

​	TensorFlow与Scikit-Learn的区别除了支撑的算法不一样，还有一个重要的区别，天生支持分布式和易购计算环境。

## 15.4 在TensorFlow下识别验证码（1）

1. 数据清洗与特征提取

   使用MNIST数据集合，使用TensorFlow的softmax回归算法。

   不同在于使用one-hot编码处理标记数据，原有的标记数据使用长度为1的向量标记结果，取值0~9.

   one-hot编码又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码。

2. 训练

   使用经典的softmax回归算法来处理

## 15.5 在TensorFlow下识别验证码（2）

1. 数据清洗与特征提取

   MNIST数据集合，多层感知机，one-hot编码

2. 训练

   使用多层感知机来处理

##  15.6 在TensorFlow下识别验证码（2）

1. 数据清洗与特征提取

   MNIST数据集合，DNN，one-hot编码

2. 训练

   使用多层感知机来处理

## 15.7 在TensorFlow下识别垃圾邮件（1）

​	SpamBase的数据不是原始的邮件内容而是已经特征化的数据，对应特征是统计的关键字以及特殊符号的词频，一共58个属性。

​	贝叶斯



## 15.8 在TensorFlow下识别垃圾邮件（2）

​	DNN